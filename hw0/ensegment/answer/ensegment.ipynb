{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensegment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the default program's result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "unclimatechangebody\n",
      "we are the people\n",
      "mentionyourfaves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mentionyourfaves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "30secondstoearth\n",
      "current ratesoughttogodown\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "nowthatcherisdead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The F-score of default program for dev.txt input was 0.82. Group members wondered what scores the wrong sentences got, and how much it was higher than the correct sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: top5 program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the top 5 of scores of the ensegment results. The scores are logged to be mroe readable. \"unclimatechangebody\", \"gerger, and \"gergerger\" are used for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unclimatechangebody']\n",
      "-11.76946906492656\n",
      "['unclimatechangebod', 'y']\n",
      "-15.248877454922333\n",
      "['u', 'nclimatechangebody']\n",
      "-15.284594107909584\n",
      "['unclimatechange', 'body']\n",
      "-15.40361194398702\n",
      "['un', 'climate', 'change', 'body']\n",
      "-15.532385601337921\n",
      "['unclimatechangebody']\n"
     ]
    }
   ],
   "source": [
    "from temp_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ger', 'ger']\n",
      "-10.52313386778198\n",
      "['gerger']\n",
      "-11.76946906492656\n",
      "['gerg', 'er']\n",
      "-11.780843268791939\n",
      "['g', 'er', 'ger']\n",
      "-13.207159111345849\n",
      "['ge', 'r', 'ger']\n",
      "-13.223195726461629\n",
      "['ger', 'ger']\n"
     ]
    }
   ],
   "source": [
    "from temp_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gergerger']\n",
      "-11.76946906492656\n",
      "['gergerge', 'r']\n",
      "-15.029017865766795\n",
      "['g', 'ergerger']\n",
      "-15.181438477228347\n",
      "['ger', 'ger', 'ger']\n",
      "-15.784700801672969\n",
      "['gergerg', 'er']\n",
      "-16.30309183007963\n",
      "['gergerger']\n"
     ]
    }
   ],
   "source": [
    "from temp_test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We found that the unseen 1 word sentence has the constant value of missingfn: -11.76946906492656(1/N) from the result, and this was higher than the correct result for some sentences. The one observaition is that when the correct result has small segements, the result was correct, but when the segements are many, the scores go below the constant score of missingfn because program multiplies P(w)s the number of segements times for the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: testcase1 program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the result of the first test case. We set the missingfn value to 0 as the minimum score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change: else: return self.missingfn(key, self.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to: else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "un climate change body\n",
      "we are the people\n",
      "mention your faves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mention your faves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "3 0 seconds to earth\n",
      "current rate sought to go down\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "now thatcher is dead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h o w t o b r e a k u p i n 5 words\n",
      "what makes god smile\n",
      "1 0 people who mean alot to me\n",
      "w o r s t d a y i n 4 words\n",
      "l o v e s t o r y i n 5 words\n",
      "t o p 3 favourite comics\n",
      "1 0 breakup lines\n",
      "things that make you smile\n",
      "best female athlete\n",
      "w o r s t b o s s i n 5 words\n",
      "now is the time for all good\n",
      "it is a truth universally acknowledged\n",
      "when in the course of human events it becomes necessary\n",
      "it was a bright cold day in april and the clocks were striking thirteen\n",
      "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness\n",
      "as gregor samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect\n",
      "in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms and an oozy smell nor yet a dry bare sandy hole with nothing in it to sitdown on or to eat it was a hobbit hole and that means comfort\n",
      "far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the galaxy lies a small un regarded yellow sun\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/test.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The F-score of dev.output was 0.98, but the result of test.output looked messy. We found that if missingfn value is 0, then ensegment program does not work properly when it meets unseen words. So we decided to give missingfn non-zero probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: testcase2 program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the result of the second test case. We set the missingfn value to 1/(N*N) as the minimum score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change: self.missingfn = missingfn or (lambda k, N: 1./(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to: self.missingfn = missingfn or (lambda k, N: 1./(N*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "un climate change body\n",
      "we are the people\n",
      "mention your faves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mention your faves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "30secondstoearth\n",
      "current rate sought to go down\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "now thatcher is dead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "howtobreakupin5words\n",
      "what makes god smile\n",
      "10peoplewhomeanalot to me\n",
      "worstdayin4words\n",
      "lovestoryin5words\n",
      "top3favouritecomics\n",
      "10breakuplines\n",
      "things that make you smile\n",
      "best female athlete\n",
      "worstbossin5words\n",
      "now is the time for all good\n",
      "it is a truth universally acknowledged\n",
      "when in the course of human events it becomes necessary\n",
      "it was a bright cold day in april and the clocks were striking thirteen\n",
      "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness\n",
      "as gregor samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect\n",
      "in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms and an oozysmellnoryetadryb are sandy hole with nothing in it to sitdown on or to eat it was a hobbit hole and that means comfort\n",
      "far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the galaxy lies a small un regarded yellow sun\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/test.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The result of F-score was 0.97, and we realised that the reducing missingfn to some constant value does not solve the core problem. This problem always happend when the long words is unseen; therefore, we applied cost for missingfn according to the its word length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: testcase3 program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the result of the third test case. We set the missingfn value to 1/(N**len(k)) as the minimum score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change: self.missingfn = missingfn or (lambda k, N: 1./(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to: self.missingfn = missingfn or (lambda k, N: 1./(N**len(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "un climate change body\n",
      "we are the people\n",
      "mention your faves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mention your faves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "3 0 seconds to earth\n",
      "current rate sought to go down\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "now thatcher is dead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to breakup in 5 words\n",
      "what makes god smile\n",
      "1 0 people who mean alot to me\n",
      "worst day in 4 words\n",
      "love story in 5 words\n",
      "top 3 favourite comics\n",
      "1 0 breakup lines\n",
      "things that make you smile\n",
      "best female athlete\n",
      "worst boss in 5 words\n",
      "now is the time for all good\n",
      "it is a truth universally acknowledged\n",
      "when in the course of human events it becomes necessary\n",
      "it was a bright cold day in april and the clocks were striking thirteen\n",
      "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness\n",
      "as gregor samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect\n",
      "in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms and an oozy smell nor yet a dry bare sandy hole with nothing in it to sitdown on or to eat it was a hobbit hole and that means comfort\n",
      "far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the galaxy lies a small un regarded yellow sun\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/test.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We could see the great improvement from the test.output; however, there was one more problem which is that integer is considered as unseen words in the count_1w.text. We tried numbers to be together in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: final testcase program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "This case shows the result of the final test case. We modified splits function not to split numbers. F-score for dev.out was 1.0, and test.out looks great except for the \"un regarded\"(unregarded)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change: return [(text[:i+1], text[i+1:]) for i in range(min(len(text), L))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to:  lst=[]\n",
    "     for i in range(min(len(text), L)):\n",
    "         if not (text[i:i+1].isdigit() and text[i+1:i+2].isdigit()):\n",
    "             lst.append((text[:i+1],text[i+1:]))\n",
    "     return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "un climate change body\n",
      "we are the people\n",
      "mention your faves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mention your faves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "30 seconds to earth\n",
      "current rate sought to go down\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "now thatcher is dead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to breakup in 5 words\n",
      "what makes god smile\n",
      "10 people who mean alot to me\n",
      "worst day in 4 words\n",
      "love story in 5 words\n",
      "top 3 favourite comics\n",
      "10 breakup lines\n",
      "things that make you smile\n",
      "best female athlete\n",
      "worst boss in 5 words\n",
      "now is the time for all good\n",
      "it is a truth universally acknowledged\n",
      "when in the course of human events it becomes necessary\n",
      "it was a bright cold day in april and the clocks were striking thirteen\n",
      "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness\n",
      "as gregor samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect\n",
      "in a hole in the ground there lived a hobbit not a nasty dirty wet hole filled with the ends of worms and an oozy smell nor yet a dry bare sandy hole with nothing in it to sitdown on or to eat it was a hobbit hole and that means comfort\n",
      "far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the galaxy lies a small un regarded yellow sun\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"../data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"../data/input/test.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
